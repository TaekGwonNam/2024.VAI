{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNRchPzDHRX3xd78aXuinAh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaekGwonNam/2024.VAI/blob/main/%EC%8B%A4%EC%8A%B502_MLP%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxBLavWZ7m-A"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train=dset.MNIST(\"\",train=True, transform=transforms.ToTensor(),\n",
        "                       target_transform=None, download=True)\n",
        "mnist_test=dset.MNIST(\"\", train=False,transform=transforms.ToTensor(),\n",
        "                      target_transform=None, download=True)\n"
      ],
      "metadata": {
        "id": "xnXC-ZJirUHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"mnist_train길이:\", len(mnist_train))\n",
        "print (\"mnist_test 길이:\", len(mnist_test))\n",
        "\n",
        "image, label = mnist_train.__getitem__(0)\n",
        "print(\"image data 형태: \", image.size())\n",
        "print (\"label: \", label)\n",
        "\n",
        "img = image.numpy()\n",
        "plt.title(\"label: %d\" %label )\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z5KDphcusUKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1023\n",
        "learning_rate = 0.01\n",
        "numepoch = 400"
      ],
      "metadata": {
        "id": "SeVlQi3Ms8Pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(mnist_train,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True, num_workers=2,\n",
        "                                           drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=False, num_workers=2,\n",
        "                                           drop_last=True)"
      ],
      "metadata": {
        "id": "4Dh9D6tjtDqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 3\n",
        "for i, [imgs, labels] in enumerate(test_loader):\n",
        "  if i>5:\n",
        "    break\n",
        "\n",
        "  print (\"[%d]\" %i)\n",
        "  print (\"한번에 로드되는 데이터 크기:\", len(imgs))\n",
        "\n",
        "  for j in range(n):\n",
        "    img=imgs[j].numpy()\n",
        "    img = img.reshape((img.shape[1], img.shape[2]))\n",
        "\n",
        "    plt.subplot(1, n, j+1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(\"label: %d\" %labels[j] )\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "G0tovlrEtYvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(28*28,255),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(256,128),\n",
        "    nn.Linear(128,10)\n",
        ")"
      ],
      "metadata": {
        "id": "A6q33UkzuNVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "  ex = np.exp(x)\n",
        "  return ex / np.sum(ex, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "_A7zAbnJw-7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class MyMLP(nn.Module):\n",
        "    def __init__(self, n_input, n_hidden1, n_hidden2, n_output):\n",
        "        super(MyMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(n_input, n_hidden1)\n",
        "        self.fc2 = nn.Linear(n_hidden1, n_hidden2)\n",
        "        self.fc3 = nn.Linear(n_hidden2, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # 이미지를 평탄화합니다\n",
        "        x = F.sigmoid(self.fc1(x))\n",
        "        x = F.sigmoid(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "pCf_wdzwut2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def ComputeAccr(dloader, imodel):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for j, [imgs, labels] in enumerate(dloader):\n",
        "        imgs = imgs.view(imgs.size(0), -1)  # 이미지를 평탄화합니다\n",
        "        img = Variable(imgs)\n",
        "        label = Variable(labels)\n",
        "        output = imodel(img)\n",
        "        _, output_index = torch.max(output, 1)\n",
        "\n",
        "        total += label.size(0)\n",
        "        correct += (output_index == label).sum().float()\n",
        "\n",
        "    print(\"Accuracy of Test Data: {}\".format(100*correct/total))\n",
        "\n",
        "ComputeAccr(test_loader, model)\n"
      ],
      "metadata": {
        "id": "zT8bvvUYuwq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# 데이터 로드\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "batch_size = 1024\n",
        "learning_rate = 0.01\n",
        "num_epochs = 10\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)\n",
        "\n",
        "# 이미지 확인\n",
        "n = 3\n",
        "for i, [imgs, labels] in enumerate(test_loader):\n",
        "    if i > 5:\n",
        "        break\n",
        "\n",
        "    print(f\"[{i}]\")\n",
        "    print(\"한번에 로드되는 데이터 크기:\", len(imgs))\n",
        "\n",
        "    for j in range(n):\n",
        "        img = imgs[j].numpy()\n",
        "        img = img.reshape((img.shape[1], img.shape[2]))\n",
        "        plt.subplot(1, n, j+1)\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.title(\"label: %d\" % labels[j])\n",
        "    plt.show()\n",
        "\n",
        "# 모델 정의\n",
        "class MyMLP(nn.Module):\n",
        "    def __init__(self, n_input, n_hidden1, n_hidden2, n_output):\n",
        "        super(MyMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(n_input, n_hidden1)\n",
        "        self.fc2 = nn.Linear(n_hidden1, n_hidden2)\n",
        "        self.fc3 = nn.Linear(n_hidden2, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # 이미지를 평탄화합니다\n",
        "        x = torch.sigmoid(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 모델 생성\n",
        "model = MyMLP(28*28, 255, 128, 10)\n",
        "\n",
        "# 손실 함수와 최적화 알고리즘 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 모델 학습\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = Variable(images)\n",
        "        labels = Variable(labels)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "                   %(epoch+1, num_epochs, i+1, len(mnist_train)//batch_size, loss.item()))\n",
        "\n",
        "# 학습된 모델의 정확도 계산\n",
        "def ComputeAccr(dloader, imodel):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for j, [imgs, labels] in enumerate(dloader):\n",
        "        imgs = Variable(imgs)\n",
        "        label = Variable(labels)\n",
        "        output = imodel(imgs)\n",
        "        _, output_index = torch.max(output, 1)\n",
        "\n",
        "        total += label.size(0)\n",
        "        correct += (output_index == label).sum().float()\n",
        "\n",
        "    print(\"Accuracy of Test Data: %.2f\" % (100*correct/total))\n",
        "\n",
        "ComputeAccr(test_loader, model)\n"
      ],
      "metadata": {
        "id": "N8l1v9PQybn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mysum = 0\n",
        "m = len(mnist_test)\n",
        "cnt = 0\n",
        "\n",
        "for i in range(m):\n",
        "    image, label = mnist_test.__getitem__(i)\n",
        "    output = model(image.unsqueeze(0))  # 배치 차원 추가\n",
        "\n",
        "    if (i % 1000 == 0):\n",
        "        img = image.numpy()\n",
        "        pred_label = output.argmax().item()  # argmax() 수정\n",
        "        plt.title(\"pred: %d, label: %d\" %(pred_label, label))\n",
        "        plt.imshow(img[0], cmap='gray')\n",
        "        plt.show()\n",
        "\n",
        "    cnt += 1\n",
        "    mysum += (output.argmax().item() == label)\n",
        "\n",
        "print(\"정확도: %.2f\" % ((float(mysum) / cnt) * 100.0))\n"
      ],
      "metadata": {
        "id": "k35by_3swbRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "7kQhAtgAzScV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch = 400\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "for i in range(num_epoch):\n",
        "    running_loss = 0.0\n",
        "    for j, [imgs, labels] in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        imgs = imgs.view(imgs.size(0), -1)\n",
        "        output = model(imgs)\n",
        "        loss = loss_func(output, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        print(\"%d..\" % i)\n",
        "        ComputeAccr(test_loader, model)\n",
        "        print(\"Epoch %d, Loss: %.4f\" % (i, running_loss / len(train_loader)))\n"
      ],
      "metadata": {
        "id": "5eVfVwyVz7dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ComputeAccr(test_loader, model)"
      ],
      "metadata": {
        "id": "b4MgsRn10J_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netname = './nets/mlp_weight.pkl'\n",
        "torch.save(model, netname, )\n",
        "\n",
        "#model = torch.load(netname)"
      ],
      "metadata": {
        "id": "AgarReID1aBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez_compressed('./nets/mlp_weight.npz',\n",
        "                    w1=w1, b1=b1,\n",
        "                    w2=w2, b2=b2,\n",
        "                    w3=w3, b3=b3)"
      ],
      "metadata": {
        "id": "ab_5KQle1huk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}